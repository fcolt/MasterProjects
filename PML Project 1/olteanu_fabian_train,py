import pandas as pd
from sklearn.model_selection import train_test_split
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import StratifiedKFold
from statistics import mean
import pickle

features_df = pd.read_csv('features.csv')

labels = features_df['label']
data = features_df.drop(columns = ['label'])
data = data.set_index('id')

cross_validator = StratifiedKFold(n_splits = 10, shuffle = True)
accuracies = []
rfc = RandomForestClassifier(
    n_estimators = 1920, min_samples_split = 2, 
    min_samples_leaf = 1,
    max_features = 'sqrt', 
    max_depth = 180,
    bootstrap = False
)
#dt = DecisionTreeClassifier()
#mlpc = MLPClassifier(max_iter = 1000, activation = 'relu')

for i, (train_idx, test_idx) in enumerate(cross_validator.split(data, labels)):
    rfc.fit(data.iloc[train_idx], labels.iloc[train_idx])
    accuracies.append(rfc.score(data.iloc[test_idx], labels.iloc[test_idx]))
    print(f'Fold {i} done')

pickle.dump(rfc, open('rfc_try_3.sav', 'wb')) #save the best model to a file
print(f'Possible model accuracies: {accuracies}')
print('Maximum accuracy: {:.4f}%'.format(max(accuracies) * 100))
print('Minimum accuracy: {:.4f}%'.format(min(accuracies) * 100))
print('Overall accuracy: {:.4f}%'.format(mean(accuracies) * 100))



#Try no 1: 12 features: mean x,y,z; medioan x,y,z; cross cor xy;yz (since z has little to no variance); magnitude; avg distance from mean x;y;z
#accuracy for test (random forest) is ~0.9+-0.1 and for test submission 0.779 ‚ùå
#Try no 2: 28 features: previous features + FFT + centroid + peaks
#accuracy improved for RFC;
# Possible model accuracies: [0.9511111111111111, 0.9388888888888889, 0.9344444444444444, 0.9477777777777778, 0.9388888888888889, 0.9422222222222222, 0.9355555555555556, 0.9388888888888889, 0.9277777777777778, 0.9455555555555556]
# Maximum accuracy: 95.1111%
# Minimum accuracy: 92.7778%
# Overall accuracy: 94.0111%
# decision tree has the following results
# Possible model accuracies: [0.8644444444444445, 0.8577777777777778, 0.8555555555555555, 0.8766666666666667, 0.8588888888888889, 0.8644444444444445, 0.86, 0.8533333333333334, 0.8677777777777778, 0.8633333333333333]
# Maximum accuracy: 87.6667%
# Minimum accuracy: 85.3333%
# Overall accuracy: 86.2222%
#Try no 3: hyperparam tuning for RFC: best params: {'n_estimators': 1920, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 180, 'bootstrap': False}
# Possible model accuracies: [0.9377777777777778, 0.9544444444444444, 0.9488888888888889, 0.9377777777777778, 0.9388888888888889, 0.9666666666666667, 0.9411111111111111, 0.9433333333333334, 0.94, 0.9388888888888889]
# Maximum accuracy: 96.6667%
# Minimum accuracy: 93.7778%
# Overall accuracy: 94.4778%