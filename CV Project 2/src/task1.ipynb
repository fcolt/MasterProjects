{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try structural integrity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_WIDTH = 640\n",
    "INPUT_HEIGHT = 640\n",
    "MIN_CONFIDENCE = 0.4\n",
    "NON_MAXIMUM_SUPPRESION_THRESH = 0.45\n",
    "SCORE_TRESH = 0.25\n",
    "CLASSES = ['bicycle', 'car', 'motorbike', 'bus', 'truck']\n",
    "LANES = [\n",
    "    np.array([[258, 408], [105, 201], [113, 125], [408, 388]], np.int32).reshape((-1,1,2)),\n",
    "    np.array([[408, 388], [88, 98], [98, 51], [528, 378]], np.int32).reshape((-1,1,2)),\n",
    "    np.array([[528, 378], [48, 8], [78, 0], [638, 368]], np.int32).reshape((-1,1,2)),\n",
    "    np.array([[1142, 373], [1918, 292], [1915, 318], [1188, 393]], np.int32).reshape((-1,1,2)),\n",
    "    np.array([[1188, 393], [1915, 318], [1918, 343], [1243, 415]], np.int32).reshape((-1,1,2)),\n",
    "    np.array([[1243, 415], [1918, 343], [1918, 373], [1295, 440]], np.int32).reshape((-1,1,2)),\n",
    "    np.array([[1418, 618], [1918, 873], [1645, 878], [1243, 643]], np.int32).reshape((-1,1,2)),\n",
    "    np.array([[1243, 643], [1645, 878], [1398, 878], [1083, 664]], np.int32).reshape((-1,1,2)),\n",
    "    np.array([[1083, 664], [1398, 878], [1183, 878], [948, 683]], np.int32).reshape((-1,1,2))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image has to be converted to 640x640 for yolov5\n",
    "def format_yolov5(image):\n",
    "    row, col, _ = image.shape\n",
    "    _max = max(col, row)\n",
    "    result = np.zeros((_max, _max, 3), np.uint8)\n",
    "    result[0:row, 0:col] = image\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(image, net):\n",
    "    input_image = format_yolov5(image)\n",
    "    blob = cv2.dnn.blobFromImage(input_image , 1/255.0, (INPUT_WIDTH, INPUT_HEIGHT), swapRB=True)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    return net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classnames_to_ids(classnames):\n",
    "    return [id for id in range(len(classnames)) if classnames[id] in CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(path=\"assets/classes.txt\"):\n",
    "    class_list = []\n",
    "    with open(path, \"r\") as f:\n",
    "        class_list = [cname.strip() for cname in f.readlines()]\n",
    "    return class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 - unwrap the predictions to get the object detections \n",
    "def unwrap_detections(\n",
    "    predictions, \n",
    "    formatted_image, \n",
    "    image, \n",
    "    classes_path=\"assets/classes.txt\", \n",
    "    show_intermediary=False\n",
    "):\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    output_data = predictions[0]\n",
    "\n",
    "    image_width, image_height, _ = formatted_image.shape\n",
    "    x_factor = image_width / INPUT_WIDTH\n",
    "    y_factor = image_height / INPUT_HEIGHT\n",
    "\n",
    "    for r in range(25200):\n",
    "        row = output_data[r]\n",
    "        confidence = row[4]\n",
    "        if confidence >= MIN_CONFIDENCE:\n",
    "\n",
    "            classes_scores = row[5:]\n",
    "            _, _, _, max_indx = cv2.minMaxLoc(classes_scores)\n",
    "            class_id = max_indx[1]\n",
    "            if (classes_scores[class_id] > SCORE_TRESH):\n",
    "\n",
    "                confidences.append(confidence)\n",
    "\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "                x, y, w, h = row[0].item(), row[1].item(), row[2].item(), row[3].item() \n",
    "                left = int((x - 0.5 * w) * x_factor)\n",
    "                top = int((y - 0.5 * h) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                box = np.array([left, top, width, height])\n",
    "                boxes.append(box)\n",
    "\n",
    "    class_list = get_classes(classes_path)\n",
    "\n",
    "    desired_classes_ids = classnames_to_ids(class_list) \n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, SCORE_TRESH, NON_MAXIMUM_SUPPRESION_THRESH) \n",
    "\n",
    "    result_class_ids = []\n",
    "    result_confidences = []\n",
    "    result_boxes = []\n",
    "\n",
    "    for i in indexes:\n",
    "        if class_ids[i] in desired_classes_ids:\n",
    "            result_confidences.append(confidences[i])\n",
    "            result_class_ids.append(class_ids[i])\n",
    "            result_boxes.append(boxes[i])\n",
    "\n",
    "    for i in range(len(result_class_ids)):\n",
    "        box = result_boxes[i]\n",
    "        class_id = result_class_ids[i]\n",
    "\n",
    "        if show_intermediary:\n",
    "            for point_set in LANES:\n",
    "                cv2.polylines(image, [point_set], True, (0, 255, 255), 2)\n",
    "            cv2.rectangle(image, box, (0, 255, 255))\n",
    "            cv2.rectangle(image, (box[0], box[1] - 20), (box[0] + box[2], box[1]), (0, 255, 255), -1)\n",
    "            cv2.putText(image, class_list[class_id], (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,0,0))\n",
    "\n",
    "    if show_intermediary:\n",
    "        cv2.imshow(\"output\", image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return result_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../train/Task1/01_2.jpg')\n",
    "formatted_image = format_yolov5(image) # making the image square\n",
    "net = cv2.dnn.readNet('assets/yolov5s.onnx')\n",
    "preds = get_preds(image, net)\n",
    "bounding_boxes = unwrap_detections(preds, formatted_image, image, show_intermediary=True)\n",
    "# for bb in bounding_boxes:\n",
    "#     x, y, w, h = bb\n",
    "#     roi = image[y:y+h, x:x+w] \n",
    "#     cv2.imshow('test', roi)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
