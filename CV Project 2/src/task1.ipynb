{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try structural integrity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from shapely.geometry import Polygon\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_WIDTH = 640\n",
    "INPUT_HEIGHT = 640\n",
    "MIN_CONFIDENCE = 0.1\n",
    "NON_MAXIMUM_SUPPRESION_THRESH = 0.45\n",
    "SCORE_TRESH = 0.25\n",
    "CLASSES = ['bicycle', 'car', 'motorbike', 'bus', 'truck']\n",
    "LANE1 = [[258, 408], [105, 201], [113, 125], [408, 388]]\n",
    "LANE2 = [[408, 388], [88, 98], [98, 51], [528, 378]]\n",
    "LANE3 = [[528, 378], [48, 8], [78, 0], [638, 368]]\n",
    "LANE4 = [[1142, 373], [1918, 292], [1915, 318], [1188, 393]]\n",
    "LANE5 = [[1188, 393], [1915, 318], [1918, 343], [1243, 415]]\n",
    "LANE6 = [[1243, 415], [1918, 343], [1918, 373], [1295, 440]]\n",
    "LANE7 = [[1418, 618], [1918, 873], [1645, 878], [1243, 643]]\n",
    "LANE8 = [[1243, 643], [1645, 878], [1398, 878], [1083, 664]]\n",
    "LANE9 = [[1083, 664], [1398, 878], [1183, 878], [948, 683]]\n",
    "LANES = [\n",
    "    np.array(LANE1, np.int32).reshape((-1,1,2)),\n",
    "    np.array(LANE2, np.int32).reshape((-1,1,2)),\n",
    "    np.array(LANE3, np.int32).reshape((-1,1,2)),\n",
    "\n",
    "    np.array(LANE4, np.int32).reshape((-1,1,2)),\n",
    "    np.array(LANE5, np.int32).reshape((-1,1,2)),\n",
    "    np.array(LANE6, np.int32).reshape((-1,1,2)),\n",
    "\n",
    "    np.array(LANE7, np.int32).reshape((-1,1,2)),\n",
    "    np.array(LANE8, np.int32).reshape((-1,1,2)),\n",
    "    np.array(LANE9, np.int32).reshape((-1,1,2))\n",
    "]\n",
    "LANE_POLYGONS = [\n",
    "    Polygon(LANE1),\n",
    "    Polygon(LANE2),\n",
    "    Polygon(LANE3),\n",
    "    Polygon(LANE4),\n",
    "    Polygon(LANE5),\n",
    "    Polygon(LANE6),\n",
    "    Polygon(LANE7),\n",
    "    Polygon(LANE8),\n",
    "    Polygon(LANE9)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('assets/yolov5s.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image has to be converted to 640x640 for yolov5\n",
    "def format_yolov5(image):\n",
    "    row, col, _ = image.shape\n",
    "    _max = max(col, row)\n",
    "    result = np.zeros((_max, _max, 3), np.uint8)\n",
    "    result[0:row, 0:col] = image\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(image, net):\n",
    "    input_image = format_yolov5(image)\n",
    "    blob = cv2.dnn.blobFromImage(input_image , 1/255.0, (INPUT_WIDTH, INPUT_HEIGHT), swapRB=True)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    return net.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classnames_to_ids(classnames):\n",
    "    return [id for id in range(len(classnames)) if classnames[id] in CLASSES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(path=\"assets/classes.txt\"):\n",
    "    class_list = []\n",
    "    with open(path, \"r\") as f:\n",
    "        class_list = [cname.strip() for cname in f.readlines()]\n",
    "    return class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwrap_detections(\n",
    "    predictions, \n",
    "    formatted_image, \n",
    "    image, \n",
    "    classes_path=\"assets/classes.txt\", \n",
    "    show_intermediary=False\n",
    "):\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    output_data = predictions[0]\n",
    "\n",
    "    image_width, image_height, _ = formatted_image.shape\n",
    "    x_factor = image_width / INPUT_WIDTH\n",
    "    y_factor = image_height / INPUT_HEIGHT\n",
    "\n",
    "    for r in range(25200):\n",
    "        row = output_data[r]\n",
    "        confidence = row[4]\n",
    "        if confidence >= MIN_CONFIDENCE:\n",
    "\n",
    "            classes_scores = row[5:]\n",
    "            _, _, _, max_indx = cv2.minMaxLoc(classes_scores)\n",
    "            class_id = max_indx[1]\n",
    "            if (classes_scores[class_id] > SCORE_TRESH):\n",
    "\n",
    "                confidences.append(confidence)\n",
    "\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "                x, y, w, h = row[0].item(), row[1].item(), row[2].item(), row[3].item() \n",
    "                left = int((x - 0.5 * w) * x_factor)\n",
    "                top = int((y - 0.5 * h) * y_factor)\n",
    "                width = int(w * x_factor)\n",
    "                height = int(h * y_factor)\n",
    "                box = np.array([left, top, width, height])\n",
    "                boxes.append(box)\n",
    "\n",
    "    class_list = get_classes(classes_path)\n",
    "\n",
    "    desired_classes_ids = classnames_to_ids(class_list) \n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, SCORE_TRESH, NON_MAXIMUM_SUPPRESION_THRESH) \n",
    "\n",
    "    result_class_ids = []\n",
    "    result_confidences = []\n",
    "    result_boxes = []\n",
    "\n",
    "    for i in indexes:\n",
    "        if class_ids[i] in desired_classes_ids:\n",
    "            result_confidences.append(confidences[i])\n",
    "            result_class_ids.append(class_ids[i])\n",
    "            result_boxes.append(boxes[i])\n",
    "\n",
    "    for i in range(len(result_class_ids)):\n",
    "        box = result_boxes[i]\n",
    "        class_id = result_class_ids[i]\n",
    "\n",
    "        if show_intermediary:\n",
    "            for point_set in LANES:\n",
    "                cv2.polylines(image, [point_set], True, (0, 255, 255), 2)\n",
    "                # cv2.fillPoly(image, [point_set], color=(0, 255, 255))\n",
    "            cv2.rectangle(image, box, (0, 255, 255))\n",
    "            cv2.rectangle(image, (box[0], box[1] - 20), (box[0] + box[2], box[1]), (0, 255, 255), -1)\n",
    "            cv2.putText(image, class_list[class_id], (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, .5, (0,0,0))\n",
    "\n",
    "    if show_intermediary:\n",
    "        cv2.imshow(\"output\", image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return result_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occupied_lanes(bounding_boxes, lane_polygons):\n",
    "    occupied_lanes_list = np.zeros(9, np.int32)\n",
    "    for bb in bounding_boxes:\n",
    "        intersection_areas = []\n",
    "        x, y, w, h = bb\n",
    "        bb_poly = Polygon([(x, y), (x+w, y), (x+w+y+h, y+h), (x, y+h)])\n",
    "        for lane_poly in lane_polygons:\n",
    "            intersection_area = lane_poly.intersection(bb_poly).area\n",
    "            intersection_areas.append(intersection_area)\n",
    "    \n",
    "        maximum_area = max(intersection_areas)\n",
    "        if maximum_area != 0:\n",
    "            occupied_lanes_list[intersection_areas.index(maximum_area)] = 1\n",
    "    \n",
    "    return occupied_lanes_list\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formatted_predictions(images_path, out_path, net):\n",
    "    out_paths = out_path.split('/')\n",
    "    out_paths = [path for path in out_paths if path != '']\n",
    "\n",
    "    for i in range(len(out_paths)): \n",
    "        if not os.path.exists('/'.join(out_paths[:i+1])):\n",
    "            os.mkdir('/'.join(out_paths[:i+1]))\n",
    "\n",
    "    img_filenames = [images_path + f for f in os.listdir(images_path) if f.endswith('.jpg')]\n",
    "    query_filenames = [images_path + f for f in os.listdir(images_path) if f.endswith('.txt')]\n",
    "\n",
    "    for img_filename, query_filename in zip(img_filenames, query_filenames):\n",
    "        queried_lanes = []\n",
    "        with open(query_filename, 'r') as query:\n",
    "            queried_lanes = query.read().splitlines()[1:]\n",
    "\n",
    "        image = cv2.imread(img_filename)\n",
    "        formatted_image = format_yolov5(image) # making the image square\n",
    "        preds = get_preds(image, net)\n",
    "        bounding_boxes = unwrap_detections(preds, formatted_image, image)\n",
    "\n",
    "        occupied_lanes = get_occupied_lanes(bounding_boxes, LANE_POLYGONS)\n",
    "\n",
    "        with open(out_path + query_filename.split('/')[-1].replace('query', 'prediction'), \"a+\") as f:\n",
    "            f.truncate(0)\n",
    "            for idx, lane_number in enumerate(queried_lanes):\n",
    "                if idx == 0:\n",
    "                    f.write(f'{len(queried_lanes)}\\n')\n",
    "                f.write(f'{int(lane_number)} {occupied_lanes[int(lane_number)-1]}')\n",
    "                if idx < len(queried_lanes) - 1:\n",
    "                    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkResults(results_folder='../submission/Task1/', gd_folder='../train/Task1/ground-truth/'):\n",
    "    results = []\n",
    "    gd = []\n",
    "    filenames = []\n",
    "\n",
    "    bad_files = []\n",
    "\n",
    "    for filename in os.listdir(results_folder):\n",
    "        f = open(results_folder + filename)\n",
    "        results.append(f.readlines())\n",
    "        filenames.append(filename.split(\"_predicted\")[0])\n",
    "\n",
    "    for filename in os.listdir(gd_folder):\n",
    "        f = open(gd_folder + filename)\n",
    "        gd.append(f.readlines())\n",
    "\n",
    "\n",
    "    correct = 0\n",
    "    for i in range(len(results)):\n",
    "        if results[i] == gd[i]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            bad_files.append(filenames[i])\n",
    "\n",
    "    print(len(results))\n",
    "    print(correct)\n",
    "    print(f'{len(bad_files)} bad predictions')\n",
    "    print(f'Accuracy is {correct / len(results) * 100}%')\n",
    "\n",
    "    return bad_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_formatted_predictions('../train/Task1/', '../submission/Task1/', net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "24\n",
      "26 bad predictions\n",
      "Accuracy is 48.0%\n",
      "Bad predictions at: ['01_1_prediction.txt', '01_2_prediction.txt', '02_1_prediction.txt', '02_2_prediction.txt', '03_2_prediction.txt', '04_1_prediction.txt', '04_2_prediction.txt', '05_1_prediction.txt', '05_2_prediction.txt', '05_3_prediction.txt', '06_1_prediction.txt', '06_2_prediction.txt', '06_3_prediction.txt', '07_3_prediction.txt', '08_1_prediction.txt', '08_2_prediction.txt', '11_1_prediction.txt', '11_4_prediction.txt', '12_2_prediction.txt', '13_1_prediction.txt', '13_2_prediction.txt', '13_3_prediction.txt', '13_4_prediction.txt', '14_1_prediction.txt', '15_1_prediction.txt', '15_3_prediction.txt']\n"
     ]
    }
   ],
   "source": [
    "print(f'Bad predictions at: {checkResults()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('../train/Task1/01_1.jpg')\n",
    "formatted_image = format_yolov5(image) # making the image square\n",
    "preds = get_preds(image, net)\n",
    "bounding_boxes = unwrap_detections(preds, formatted_image, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
