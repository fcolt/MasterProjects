{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Poti centra si alinia imaginile cu SIFT si apoi sa faci crop. Cred ca ar trebui sa se ajunga la aceleasi coordonate dupa SIFT\n",
    "- Filtrezi liniile astfel incat sa fie la vreo 80 de pixeli distanta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image_, window_name='image', timeout=0):\n",
    "    \"\"\"\n",
    "    Show image.\n",
    "    :param image_\n",
    "    :param window_name\n",
    "    :param timeout\n",
    "    \"\"\"\n",
    "    # h, w = image_.shape[0:2]\n",
    "    # neww = 1024\n",
    "    # newh = int(neww * (h / w))\n",
    "    # img = cv.resize(image_, (neww, newh))\n",
    "\n",
    "    cv.imshow(window_name, image_)\n",
    "    cv.waitKey(timeout)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keypoints_and_features(image, show_details = False) -> tuple:\n",
    "    \"\"\"\n",
    "    \n",
    "    :param image.\n",
    "    :return the keypoints: [cv.Keypoint] and the features: np.ndarray for each keypoint.\n",
    "    \"\"\"\n",
    "    \n",
    "    def show_keypoints(image_, keypoints_):\n",
    "        \"\"\"\n",
    "        Show the keypoints found in the image.\n",
    "        \"\"\"\n",
    "        image_output = image_.copy()\n",
    "        image_output = cv.drawKeypoints(image, keypoints_, image_output, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        show_image(image_output, 'keypoints')\n",
    "        # cv.imwrite('keypoints.jpg', image_output)\n",
    "    \n",
    "    gray_image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    sift = cv.SIFT_create()\n",
    "    \n",
    "    keypoints, features = sift.detectAndCompute(gray_image, None)\n",
    "     \n",
    "    if show_details:\n",
    "        show_keypoints(image, keypoints)\n",
    "        \n",
    "    return keypoints, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread(r'board+dominoes\\02.jpg')\n",
    "k, f = get_keypoints_and_features(image, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_images(img1, img2, good_match_percent=0.75, ref_filename=''):\n",
    "    k1, f1 = get_keypoints_and_features(img1)\n",
    "    k2, f2 = get_keypoints_and_features(img2)\n",
    "\n",
    "    matcher = cv.DescriptorMatcher_create('FlannBased')\n",
    "    # matches = matcher.match(f1, f2, None)\n",
    "    all_matches = matcher.knnMatch(f1, f2, k=2) \n",
    "\n",
    "    # Add the best matches in a list\n",
    "    matches = [match[0] for match in all_matches if match[0].distance / match[1].distance < good_match_percent]\n",
    "\n",
    "    # list(matches).sort(key=lambda x: x.distance, reverse=False)\n",
    " \n",
    "    # num_good_matches = int(len(matches) * good_match_percent)\n",
    "    # matches = matches[:num_good_matches]\n",
    "\n",
    "    # Draw top matches\n",
    "    im_matches = cv.drawMatches(img1, k1, img2, k2, matches, None)\n",
    "    if ref_filename != '':\n",
    "        cv.imwrite(\"matches_\" + ref_filename + \".jpg\", im_matches)\n",
    "\n",
    "    # Extract location of good matches\n",
    "    points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "    points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "    for i, match in enumerate(matches):\n",
    "        points1[i, :] = k1[match.queryIdx].pt\n",
    "        points2[i, :] = k2[match.trainIdx].pt\n",
    "\n",
    "    # Find homography\n",
    "    h, _ = cv.findHomography(points1, points2, cv.RANSAC)\n",
    "\n",
    "    # Use homography\n",
    "    height, width, _ = img2.shape\n",
    "    im1_reg = cv.warpPerspective(img1, h, (width, height))\n",
    "\n",
    "    return im1_reg, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_aligned_image(ref_filename, image_path, out_path='aligned_train\\\\'):\n",
    "    im_reference = cv.imread(ref_filename, cv.IMREAD_COLOR)\n",
    "\n",
    "    if not os.path.exists(out_path):\n",
    "        os.mkdir(out_path) \n",
    "\n",
    "    # Read image to be aligned\n",
    "    im = cv.imread(image_path, cv.IMREAD_COLOR)\n",
    "\n",
    "    # Registered image will be stored in im_reg.\n",
    "    # The estimated homography will be stored in h.\n",
    "    im_reg, h = align_images(im, im_reference)\n",
    "\n",
    "    # Crop image\n",
    "    cropped_image = im_reg[273 * 2 : (273 + 960) * 2,\n",
    "                           547 * 2 : (547 + 956) * 2]\n",
    "    # Write aligned image to disk.\n",
    "    out_filename = \"aligned_\" + image_path.split('\\\\')[-1]\n",
    "    cv.imwrite(out_path + out_filename, cropped_image)\n",
    "\n",
    "def save_aligned_images(ref_filename='board+dominoes\\\\02.jpg', images_path='train\\\\regular_tasks\\\\', out_path='aligned_train\\\\'):\n",
    "    print(\"Reading reference image : \" + ref_filename)\n",
    "    # Read images to be aligned\n",
    "    img_filenames = [images_path + f for f in os.listdir(images_path) if f.endswith('.jpg')]\n",
    "    for idx, img_filename in enumerate(img_filenames):\n",
    "        save_aligned_image(ref_filename, img_filename, out_path)\n",
    "        progress_bar(idx, len(img_filenames))\n",
    "\n",
    "def progress_bar(current, total, bar_length=20):\n",
    "    fraction = current / total\n",
    "\n",
    "    arrow = int(fraction * bar_length - 1) * '-' + '>'\n",
    "    padding = int(bar_length - len(arrow)) * ' '\n",
    "\n",
    "    ending = '\\n' if current == total else '\\r'\n",
    "\n",
    "    print(f'Progress: [{arrow}{padding}] {int(fraction*100)}%', end=ending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = 'aligned_train_try2\\\\'\n",
    "img_filenames = [images_path + f for f in os.listdir(images_path) if f.endswith('.jpg')]\n",
    "for img_filename in img_filenames:\n",
    "    # img = cv.imread(img_filename)\n",
    "\n",
    "    # scale = 0.5 # percent of original size\n",
    "    # width = int(img.shape[1] * scale)\n",
    "    # height = int(img.shape[0] * scale)\n",
    "    # dim = (width, height)\n",
    "    \n",
    "    # img = cv.resize(img, dim)\n",
    "    # r = cv.selectROI(img)\n",
    "    # cv.waitKey(0)\n",
    "    # cv.destroyAllWindows()\n",
    "    # cropped_image = img[int(r[1]) : int(r[1] + r[3]), \n",
    "    #                     int(r[0]) : int(r[0] + r[2])]\n",
    "    # print(r)\n",
    "    img = cv.imread(img_filename)\n",
    "\n",
    "    cropped_image = img[273 * 2 : (273 + 960) * 2,\n",
    "                        547 * 2 : (547 + 956) * 2]\n",
    "    \n",
    "    cv.imwrite('aligned_cropped\\\\' + img_filename.split('\\\\')[-1], cropped_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
